# app.py â€” AI í–‰ì •ê´€ Pro (ì™„ì„¸íŠ¸)
# LAWGO(ë²•ì œì²˜ DRF) + NAVER(ë‰´ìŠ¤/ì›¹/ì „ë¬¸ ë¸”ë¡œê·¸Â·ì¹´í˜) + Geminiâ†’Groq + Supabase
# âœ… (1) API í˜¸ì¶œ ìˆ˜ / í† í° ì‚¬ìš©ëŸ‰ í‘œì‹œ(ê°€ëŠ¥í•œ ë²”ìœ„)
# âœ… (2) NAVER ë‰´ìŠ¤/ì›¹/ë¸”ë¡œê·¸/ì¹´í˜: "ìƒí™© ê´€ë ¨ì„±" í•„í„° + ë¸”ë¡œê·¸/ì¹´í˜ "ì „ë¬¸ì„±" í•„í„°
# âœ… (3) LAWGO: ëŒ€í‘œ+ì—°ê´€ ë²•ë ¹ 3ê°œ + JO(6ìë¦¬) + ì›ë¬¸ í´ë¦­(HTML ë§í¬)
# âœ… (4) ê²€ìƒ‰ ê²°ê³¼ "í‹€ ë°– íŠ" ë°©ì§€: êµ¬ì¡°í™” íŒŒì‹± + ì¹´ë“œ ë Œë”
# âœ… (5) ì˜µì…˜: LLM ì •ë°€ ë¦¬ë­í‚¹ í† ê¸€(ON/OFF) (ë¹„ìš©â†‘ ì •í™•ë„â†‘)

import streamlit as st
import json
import re
import time
from datetime import datetime, timedelta
from html import escape

# ---------------------------
# Optional deps (ì•ˆì£½ê²Œ)
# ---------------------------
try:
    import requests
except Exception:
    requests = None

try:
    import google.generativeai as genai
except Exception:
    genai = None

try:
    from groq import Groq
except Exception:
    Groq = None

try:
    from supabase import create_client
except Exception:
    create_client = None


# =========================================================
# 1) Page & Style
# =========================================================
st.set_page_config(layout="wide", page_title="AI í–‰ì •ê´€ Pro", page_icon="ğŸ›ï¸")

st.markdown(
    """
<style>
.stApp { background-color: #f3f4f6; }

.paper-sheet {
  background-color: white;
  width: 100%;
  max-width: 210mm;
  min-height: 297mm;
  padding: 25mm;
  margin: auto;
  box-shadow: 0 10px 30px rgba(0,0,0,0.1);
  font-family: 'Batang', serif;
  color: #111;
  line-height: 1.6;
  position: relative;
}

.doc-header { text-align: center; font-size: 22pt; font-weight: 900; margin-bottom: 30px; letter-spacing: 2px; }
.doc-info { display: flex; justify-content: space-between; font-size: 11pt; border-bottom: 2px solid #333; padding-bottom: 10px; margin-bottom: 20px; gap: 10px; flex-wrap: wrap;}
.doc-body { font-size: 12pt; text-align: justify; white-space: pre-line; }
.doc-footer { text-align: center; font-size: 20pt; font-weight: bold; margin-top: 80px; letter-spacing: 5px; }
.stamp { position: absolute; bottom: 85px; right: 80px; border: 3px solid #cc0000; color: #cc0000; padding: 5px 10px; font-size: 14pt; font-weight: bold; transform: rotate(-15deg); opacity: 0.8; border-radius: 5px; }

.agent-log { font-family: 'Consolas', monospace; font-size: 0.85rem; padding: 6px 12px; border-radius: 6px; margin-bottom: 8px; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }
.log-legal { background-color: #eff6ff; color: #1e40af; border-left: 4px solid #3b82f6; }
.log-search { background-color: #fff7ed; color: #c2410c; border-left: 4px solid #f97316; }
.log-strat { background-color: #f5f3ff; color: #6d28d9; border-left: 4px solid #8b5cf6; }
.log-calc { background-color: #f0fdf4; color: #166534; border-left: 4px solid #22c55e; }
.log-draft { background-color: #fef2f2; color: #991b1b; border-left: 4px solid #ef4444; }
.log-sys { background-color: #f3f4f6; color: #4b5563; border-left: 4px solid #9ca3af; }

.api-box { background: #ffffff; border: 1px solid #e5e7eb; padding: 14px; border-radius: 10px; }
.api-pill { display:inline-block; padding:4px 10px; border-radius:999px; font-size: 12px; margin-right:6px; margin-bottom:6px; border:1px solid #e5e7eb; background:#f9fafb; }
.api-ok { border-color:#bbf7d0; background:#f0fdf4; }
.api-bad { border-color:#fecaca; background:#fef2f2; }
.small-muted { color:#6b7280; font-size:12px; }

.item-card { background:#fff; border:1px solid #e5e7eb; border-radius:12px; padding:12px 14px; margin-bottom:10px; }
.item-title { font-weight:700; }
.item-meta { color:#6b7280; font-size:12px; margin-top:4px; line-height:1.3; }
.item-desc { margin-top:8px; white-space:pre-line; }
</style>
""",
    unsafe_allow_html=True,
)


# =========================================================
# 2) Helpers
# =========================================================
def mask_pii(text: str) -> str:
    if not text:
        return text
    text = re.sub(r"\b\d{2,3}-\d{3,4}-\d{4}\b", "OOO-OOOO-OOOO", text)
    text = re.sub(r"\b\d{6}-\d{7}\b", "OOOOOO-OOOOOOO", text)
    text = re.sub(r"\b\d{2,3}[ê°€-í£]\d{4}\b", "OOO", text)
    return text


def normalize_text(s: str) -> str:
    if not s:
        return ""
    s = re.sub(r"<.*?>", "", s)
    s = s.replace("&quot;", '"').replace("&amp;", "&").replace("&lt;", "<").replace("&gt;", ">")
    s = re.sub(r"\s+", " ", s).strip()
    return s


def safe_url(u: str) -> str:
    if not u:
        return ""
    u = u.strip()
    if not (u.startswith("http://") or u.startswith("https://")):
        return ""
    return u


def clamp(s: str, n: int = 300) -> str:
    s = s or ""
    return s if len(s) <= n else s[:n] + "â€¦"


# =========================================================
# 3) Meter / Trace (API í˜¸ì¶œ ìˆ˜ + í† í°)
# =========================================================
class UsageMeter:
    def __init__(self):
        self.calls = {}
        self.tokens = {
            "gemini_prompt": 0,
            "gemini_output": 0,
            "gemini_total": 0,
            "groq_prompt": 0,
            "groq_output": 0,
            "groq_total": 0,
        }

    def inc_call(self, name: str):
        self.calls[name] = self.calls.get(name, 0) + 1

    def add_gemini_tokens(self, prompt: int | None, output: int | None, total: int | None):
        if prompt is not None:
            self.tokens["gemini_prompt"] += int(prompt)
        if output is not None:
            self.tokens["gemini_output"] += int(output)
        if total is not None:
            self.tokens["gemini_total"] += int(total)
        else:
            if prompt is not None or output is not None:
                self.tokens["gemini_total"] += int((prompt or 0) + (output or 0))

    def add_groq_tokens(self, prompt: int | None, output: int | None, total: int | None):
        if prompt is not None:
            self.tokens["groq_prompt"] += int(prompt)
        if output is not None:
            self.tokens["groq_output"] += int(output)
        if total is not None:
            self.tokens["groq_total"] += int(total)
        else:
            if prompt is not None or output is not None:
                self.tokens["groq_total"] += int((prompt or 0) + (output or 0))


class Trace:
    def __init__(self):
        self.items = []
        self.meter = UsageMeter()

    def add(self, name, ok, detail="", tokens: dict | None = None):
        self.meter.inc_call(name)
        row = {"name": name, "ok": bool(ok), "detail": detail}
        if tokens:
            row["tokens"] = tokens
        self.items.append(row)

    def to_markdown(self):
        if not self.items:
            return "API ì‚¬ìš© ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤."
        lines = ["| API | ì„±ê³µ | ìƒì„¸ | í† í° |", "|---|---:|---|---|"]
        for it in self.items:
            tok = it.get("tokens")
            tok_str = ""
            if isinstance(tok, dict):
                p = tok.get("prompt")
                o = tok.get("output")
                t = tok.get("total")
                tok_str = f"p={p}, o={o}, t={t}"
            lines.append(f"| {it['name']} | {'âœ…' if it['ok'] else 'âŒ'} | {it.get('detail','')} | {tok_str} |")
        return "\n".join(lines)

    def usage_summary(self) -> dict:
        return {"calls": self.meter.calls, "tokens": self.meter.tokens}


# =========================================================
# 4) Services
# =========================================================
class LLMService:
    """
    secrets:
      [general]
      GEMINI_API_KEY
      GROQ_API_KEY
      GROQ_MODEL
    """
    def __init__(self, trace: Trace):
        self.trace = trace
        g = st.secrets.get("general", {})
        self.gemini_key = g.get("GEMINI_API_KEY")
        self.groq_key = g.get("GROQ_API_KEY")
        self.groq_model = g.get("GROQ_MODEL", "llama-3.3-70b-versatile")
        self.gemini_models = ["gemini-2.5-flash", "gemini-2.5-flash-lite", "gemini-2.0-flash"]

        self._gemini_ready = False
        if self.gemini_key and genai is not None:
            try:
                genai.configure(api_key=self.gemini_key)
                self._gemini_ready = True
                self.trace.add("Gemini.configure", True, "OK")
            except Exception as e:
                self.trace.add("Gemini.configure", False, f"{e}")
        else:
            self.trace.add("Gemini.configure", False, "No key or lib missing")

        self.groq_client = None
        if self.groq_key and Groq is not None:
            try:
                self.groq_client = Groq(api_key=self.groq_key)
                self.trace.add("Groq.init", True, f"model={self.groq_model}")
            except Exception as e:
                self.trace.add("Groq.init", False, f"{e}")
        else:
            self.trace.add("Groq.init", False, "No key or lib missing")

    @staticmethod
    def _extract_gemini_tokens(res) -> tuple[int | None, int | None, int | None]:
        try:
            um = getattr(res, "usage_metadata", None)
            if not um:
                return (None, None, None)
            total = getattr(um, "total_token_count", None)
            prompt = getattr(um, "prompt_token_count", None)
            output = getattr(um, "candidates_token_count", None)
            if output is None:
                output = getattr(um, "response_token_count", None)
            return (prompt, output, total)
        except Exception:
            return (None, None, None)

    def _try_gemini_text(self, prompt: str):
        if not self._gemini_ready:
            raise RuntimeError("Gemini not ready")
        last = None
        for m in self.gemini_models:
            try:
                model = genai.GenerativeModel(m)
                res = model.generate_content(prompt)
                p, o, t = self._extract_gemini_tokens(res)
                self.trace.meter.add_gemini_tokens(p, o, t)
                self.trace.add(
                    "Gemini.generate_content",
                    True,
                    f"model={m}",
                    tokens={"prompt": p, "output": o, "total": t},
                )
                return (res.text or "").strip()
            except Exception as e:
                last = e
                self.trace.add("Gemini.generate_content", False, f"model={m} err={type(e).__name__}")
        raise RuntimeError(last)

    def generate_text(self, prompt: str) -> str:
        try:
            return self._try_gemini_text(prompt)
        except Exception:
            pass

        if not self.groq_client:
            return "ì‹œìŠ¤í…œ ì˜¤ë¥˜: LLM ì—°ê²° ì‹¤íŒ¨(Gemini/Groq ëª¨ë‘ ë¶ˆê°€)."
        try:
            completion = self.groq_client.chat.completions.create(
                model=self.groq_model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
            )
            usage = getattr(completion, "usage", None)
            p = getattr(usage, "prompt_tokens", None) if usage else None
            o = getattr(usage, "completion_tokens", None) if usage else None
            t = getattr(usage, "total_tokens", None) if usage else None
            self.trace.meter.add_groq_tokens(p, o, t)
            self.trace.add(
                "Groq.chat.completions",
                True,
                f"model={self.groq_model}",
                tokens={"prompt": p, "output": o, "total": t},
            )
            return (completion.choices[0].message.content or "").strip()
        except Exception as e:
            self.trace.add("Groq.chat.completions", False, f"{type(e).__name__}: {e}")
            return "ì‹œìŠ¤í…œ ì˜¤ë¥˜: Groq í˜¸ì¶œ ì‹¤íŒ¨"

    def generate_json(self, prompt: str) -> dict | None:
        txt = self.generate_text(prompt + "\n\në°˜ë“œì‹œ JSONë§Œ ì¶œë ¥. ì„¤ëª… ê¸ˆì§€.")
        try:
            m = re.search(r"\{.*\}", txt, re.DOTALL)
            if not m:
                return None
            return json.loads(m.group(0))
        except Exception:
            return None


class LawAPIService:
    """
    ë²•ì œì²˜ DRF
    secrets:
      [general]
      LAW_API_ID = OC
    """
    BASE_SEARCH = "https://www.law.go.kr/DRF/lawSearch.do"
    BASE_SERVICE = "https://www.law.go.kr/DRF/lawService.do"

    def __init__(self, trace: Trace):
        self.trace = trace
        g = st.secrets.get("general", {})
        self.oc = g.get("LAW_API_ID")
        if not self.oc:
            self.trace.add("LAWGO.init", False, "LAW_API_ID missing")

    def _get_json(self, url: str, params: dict, name: str, detail: str = ""):
        if requests is None:
            self.trace.add(name, False, "requests missing")
            return None
        if not self.oc:
            self.trace.add(name, False, "LAW_API_ID missing")
            return None
        try:
            r = requests.get(url, params=params, timeout=12)
            r.raise_for_status()
            data = r.json()
            self.trace.add(name, True, detail or f"endpoint={url.split('/')[-1]}")
            return data
        except Exception as e:
            self.trace.add(name, False, f"{type(e).__name__}: {e}")
            return None

    def search_law(self, query: str, display: int = 5) -> list[dict]:
        params = {"OC": self.oc, "target": "law", "type": "JSON", "query": query, "display": display, "page": 1}
        data = self._get_json(self.BASE_SEARCH, params, "LAWGO.lawSearch", "endpoint=lawSearch.do")
        if not isinstance(data, dict):
            return []

        candidates = []
        if isinstance(data.get("LawSearch"), dict) and isinstance(data["LawSearch"].get("law"), list):
            candidates = data["LawSearch"]["law"]
        elif isinstance(data.get("lawSearch"), dict) and isinstance(data["lawSearch"].get("law"), list):
            candidates = data["lawSearch"]["law"]
        else:
            for v in data.values():
                if isinstance(v, dict) and isinstance(v.get("law"), list):
                    candidates = v["law"]
                    break

        out = []
        for item in candidates:
            if not isinstance(item, dict):
                continue
            law_name = item.get("ë²•ë ¹ëª…í•œê¸€") or item.get("ë²•ë ¹ëª…_í•œê¸€") or item.get("ë²•ë ¹ëª…") or ""
            mst = item.get("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸") or item.get("MST") or item.get("lsi_seq")
            link = item.get("ë²•ë ¹ìƒì„¸ë§í¬") or ""
            if link and link.startswith("/"):
                link = "https://www.law.go.kr" + link
            out.append({"law_name": str(law_name).strip(), "mst": str(mst) if mst else None, "link": str(link)})
        return [x for x in out if x["law_name"]]

    def fetch_article(self, mst: str, jo6: str | None):
        params = {"OC": self.oc, "target": "law", "type": "JSON", "MST": mst}
        if jo6:
            params["JO"] = jo6
        detail = f"endpoint=lawService.do MST={mst}" + (f" JO={jo6}" if jo6 else "")
        return self._get_json(self.BASE_SERVICE, params, "LAWGO.lawService", detail)

    @staticmethod
    def normalize_jo(jo_text: str) -> str | None:
        if not jo_text:
            return None
        s = jo_text.replace(" ", "")
        m = re.search(r"(\d+)\s*ì¡°(?:ì˜\s*(\d+))?", s)
        if not m:
            return None
        n = int(m.group(1))
        k = int(m.group(2)) if m.group(2) else 0
        if n < 0 or n > 9999 or k < 0 or k > 99:
            return None
        return f"{n:04d}{k:02d}"

    @staticmethod
    def _extract_article_text(data: dict) -> str:
        if not isinstance(data, dict):
            return ""
        for key in ["ì¡°ë¬¸ë‚´ìš©", "joCntnt", "JO_CNTNT", "content", "Content"]:
            v = data.get(key)
            if isinstance(v, str) and v.strip():
                return v.strip()
        # ì¼ë¶€ ì‘ë‹µì€ ë‹¤ë¥¸ êµ¬ì¡°ë¡œ ì˜¬ ìˆ˜ ìˆìŒ (ìµœì†Œí•œì˜ ì•ˆì „ë§)
        for v in data.values():
            if isinstance(v, str) and len(v) > 30 and "ì œ" in v and "ì¡°" in v:
                return v.strip()
        return ""

    def get_related_laws_pack(self, situation: str, llm: LLMService, topk: int = 3):
        situation_m = mask_pii(situation)

        extract_prompt = f"""
ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ í–‰ì • ì‹¤ë¬´ìš© 'ë²•ë ¹ í›„ë³´ ì¶”ì¶œê¸°'ë‹¤.
ì•„ë˜ ìƒí™©ì— ì—°ê´€ëœ ë²•ë ¹ í›„ë³´ë¥¼ ìµœëŒ€ 6ê°œ ë½‘ì•„ë¼.
ê° í›„ë³´ëŠ” ë²•ë ¹ëª…ê³¼ ëŒ€í‘œ ì¡°í•­(ìˆìœ¼ë©´)ì„ í¬í•¨.

ë°˜ë“œì‹œ JSONë§Œ:
{{
  "candidates": [
    {{"law_name": "ë„ë¡œêµí†µë²•", "article": "ì œ32ì¡°"}},
    {{"law_name": "ì†Œë°©ê¸°ë³¸ë²•", "article": ""}}
  ]
}}

ìƒí™©: "{situation_m}"
"""
        guess = llm.generate_json(extract_prompt) or {}
        cand = guess.get("candidates") if isinstance(guess, dict) else None
        if not isinstance(cand, list):
            cand = []

        cleaned = []
        seen = set()
        for x in cand:
            if not isinstance(x, dict):
                continue
            ln = (x.get("law_name") or "").strip()
            ar = (x.get("article") or "").strip()
            if not ln or ln in seen:
                continue
            seen.add(ln)
            cleaned.append({"law_name": ln, "article": ar})
            if len(cleaned) >= 8:
                break

        # ë¶€ì¡±í•˜ë©´ ìƒí™© í‚¤ì›Œë“œë¡œ ë³´ê°•
        if len(cleaned) < topk:
            kw = re.sub(r"\s+", " ", situation_m).strip()[:40]
            kw_results = self.search_law(kw, display=10)
            for it in kw_results:
                ln = it["law_name"]
                if ln not in seen:
                    seen.add(ln)
                    cleaned.append({"law_name": ln, "article": ""})
                if len(cleaned) >= 8:
                    break

        picked = []
        picked_names = set()

        for c in cleaned:
            q = c["law_name"]
            ar = c["article"]
            sr = self.search_law(q, display=5)
            if not sr:
                continue
            best = sr[0]
            law_name = best.get("law_name") or q
            mst = best.get("mst")
            link = best.get("link", "")

            if not law_name or law_name in picked_names:
                continue
            picked_names.add(law_name)

            jo6 = self.normalize_jo(ar) if ar else None
            article_text = ""
            if mst:
                data = self.fetch_article(mst, jo6)
                article_text = self._extract_article_text(data)

            picked.append({"law_name": law_name, "article": ar, "jo6": jo6, "mst": mst, "link": link, "article_text": article_text})
            if len(picked) >= topk:
                break

        if not picked:
            picked = [{"law_name": "ë²•ë ¹ API ê²€ìƒ‰ ì‹¤íŒ¨(ê²°ê³¼ ì—†ìŒ)", "article": "", "jo6": None, "mst": None, "link": "", "article_text": ""}]

        primary = picked[0]
        legal_basis_text = primary["law_name"] + (f" {primary['article']}" if primary.get("article") else "")
        return {"primary": primary, "related": picked, "legal_basis_text": legal_basis_text}


class NaverSearchService:
    """
    secrets:
      [naver]
      CLIENT_ID
      CLIENT_SECRET
    """
    BASE = "https://openapi.naver.com/v1/search"

    def __init__(self, trace: Trace):
        self.trace = trace
        n = st.secrets.get("naver", {})
        self.client_id = n.get("CLIENT_ID")
        self.client_secret = n.get("CLIENT_SECRET")
        if not self.client_id or not self.client_secret:
            self.trace.add("NAVER.init", False, "CLIENT_ID/SECRET missing")

    def _call(self, endpoint: str, query: str, display: int = 5, sort: str = "sim"):
        if requests is None:
            self.trace.add(f"NAVER.{endpoint}", False, "requests missing")
            return None
        if not self.client_id or not self.client_secret:
            self.trace.add(f"NAVER.{endpoint}", False, "CLIENT_ID/SECRET missing")
            return None

        url = f"{self.BASE}/{endpoint}.json"
        headers = {"X-Naver-Client-Id": self.client_id, "X-Naver-Client-Secret": self.client_secret}
        params = {"query": query, "display": display, "start": 1, "sort": sort}
        try:
            r = requests.get(url, headers=headers, params=params, timeout=10)
            r.raise_for_status()
            self.trace.add(f"NAVER.{endpoint}", True, f"display={display}")
            return r.json()
        except Exception as e:
            self.trace.add(f"NAVER.{endpoint}", False, f"{type(e).__name__}: {e}")
            return None

    # ---- ì „ë¬¸ì„±(ë¸”ë¡œê·¸/ì¹´í˜) ----
    _PRO_KEYWORDS = [
        "ë²•ë ¹","ì‹œí–‰ë ¹","ì‹œí–‰ê·œì¹™","ì¡°ë¬¸","íŒë¡€","í–‰ì •ì‹¬íŒ","í–‰ì •ì†Œì†¡","ê³¼íƒœë£Œ","ì²˜ë¶„","ì‚¬ì „í†µì§€",
        "ì˜ê²¬ì œì¶œ","ì´ì˜ì‹ ì²­","ë¶ˆë³µ","ìœ ê¶Œí•´ì„","ì§ˆì˜íšŒì‹ ","ê³ ì‹œ","í›ˆë ¹","ì˜ˆê·œ","ì§€ì¹¨","ë§¤ë‰´ì–¼","ê°€ì´ë“œ",
        "ê³µê³µê¸°ê´€","ì§€ìì²´","ê³µë¬´ì›","ë²•ì œì²˜","êµ­ê°€ë²•ë ¹ì •ë³´","í–‰ì •ì ˆì°¨ë²•","ë³µì§€","ìˆ˜ê¸‰","ê¸‰ì—¬","ì¡°ì‚¬"
    ]
    _NONPRO_KEYWORDS = ["í›„ê¸°","ë§›ì§‘","ì¼ìƒ","ì—¬í–‰","ë‹¤ì´ì–´íŠ¸","ë¸Œì´ë¡œê·¸","ë‚´ëˆë‚´ì‚°","ê°ì„±","ì—°ì• ","ìœ¡ì•„","ë¦¬ë·°"]

    @classmethod
    def _professional_score(cls, title: str, desc: str, link: str) -> int:
        t = (title or "") + " " + (desc or "")
        score = 0
        for k in cls._PRO_KEYWORDS:
            if k in t:
                score += 2
        if re.search(r"ì œ?\s*\d+\s*ì¡°", t):
            score += 4
        if len(desc or "") >= 80:
            score += 1
        for k in cls._NONPRO_KEYWORDS:
            if k in t:
                score -= 4
        if re.search(r"[ğŸ˜‚ğŸ¤£ğŸ˜ğŸ˜…]|ã…‹ã…‹|ã…ã…|ã… ã… ", t):
            score -= 2
        if any(dom in (link or "") for dom in ["law.go.kr", "go.kr", "ac.kr", "moj.go.kr", "korea.kr"]):
            score += 3
        return score

    # ---- ê´€ë ¨ì„±(ì „ ì†ŒìŠ¤ ê³µí†µ) ----
    @staticmethod
    def _make_relevance_terms(situation: str, laws_pack: dict) -> list[str]:
        base = re.findall(r"[ê°€-í£A-Za-z0-9]{2,12}", situation or "")
        base = [w for w in base if w not in ["ê·¸ë¦¬ê³ ","ê´€ë ¨","ë¬¸ì˜","ì‚¬í•­","ëŒ€í•˜ì—¬","ëŒ€í•œ","ì²˜ë¦¬","ìš”ì²­","ì‘ì„±","ì•ˆë‚´","ê²€í† "]]

        rel = []
        for it in (laws_pack.get("related") or [])[:3]:
            nm = (it.get("law_name") or "")
            ar = (it.get("article") or "")
            rel += re.findall(r"[ê°€-í£A-Za-z0-9]{2,12}", nm)
            rel += re.findall(r"[ê°€-í£A-Za-z0-9]{2,12}", ar)

        terms = base + rel
        stop = set(["ë²•","ë²•ë ¹","ì œ","ì¡°","ë“±","ê´€ë ¨","ì‚¬í•­","ê¸°ì¤€","ë‚´ìš©"])
        terms = [t for t in terms if t not in stop]

        uniq = []
        seen = set()
        for t in terms:
            if t in seen:
                continue
            seen.add(t)
            uniq.append(t)
            if len(uniq) >= 18:
                break
        return uniq

    @staticmethod
    def _relevance_score(title: str, desc: str, terms: list[str]) -> int:
        t = (title or "") + " " + (desc or "")
        score = 0
        for w in terms:
            if w and w in t:
                score += 3

        # "í–‰ì •ì²˜ë¶„/ê³¼íƒœë£Œ" ì¼ë°˜ê¸°ì‚¬ë§Œ ë¼ëŠ” ê²ƒ ë°©ì§€
        if ("ê³¼íƒœë£Œ" in t or "í–‰ì •ì²˜ë¶„" in t) and not any(
            x in t for x in ["ë³µì§€","ìˆ˜ê¸‰","ê¸‰ì—¬","ì¡°ì‚¬","ì‚¬íšŒë³´ì¥","ê¸°ì´ˆìƒí™œ","ìƒê³„","ì˜ë£Œê¸‰ì—¬","ì£¼ê±°ê¸‰ì—¬","ìê²©","ì‹ ì²­"]
        ):
            score -= 6
        return score

    def _parse_items(self, data: dict, source: str) -> list[dict]:
        out = []
        if not data:
            return out
        for it in (data.get("items") or [])[:15]:
            title = normalize_text(it.get("title", ""))
            desc = normalize_text(it.get("description", "")) or normalize_text(it.get("snippet", ""))
            link = safe_url(it.get("link", "") or "")
            out.append({"source": source, "title": title or "(ì œëª© ì—†ìŒ)", "desc": clamp(desc, 320), "link": link})

        uniq, seen = [], set()
        for x in out:
            key = x.get("link") or (x["source"] + x["title"])
            if key in seen:
                continue
            seen.add(key)
            uniq.append(x)
        return uniq

    def search_precedents_parsed(self, situation: str, laws_pack: dict, enable_llm_rerank: bool = False, llm: LLMService | None = None) -> list[dict]:
        core = situation.strip()
        primary_law = (laws_pack.get("legal_basis_text") or "").strip()

        # âœ… ì§ˆì˜ ê°•í™”: ëŒ€í‘œë²•ë ¹ + ìƒí™©
        q_news = f"{core} {primary_law} ì¡°ì‚¬ ê¸°ì¤€"
        q_web  = f"{core} {primary_law} ì¡°ë¬¸ í•´ì„¤"
        q_blog = f"{core} {primary_law} ì‹¤ë¬´ í•´ì„¤"
        q_cafe = f"{core} {primary_law} ì§ˆì˜íšŒì‹ "

        news = self._call("news", q_news, display=8)
        webkr = self._call("webkr", q_web, display=8)
        blog = self._call("blog", q_blog, display=12)
        cafe = self._call("cafearticle", q_cafe, display=12)

        items = []
        items += self._parse_items(news, "news")
        items += self._parse_items(webkr, "webkr")
        items += self._parse_items(blog, "blog")
        items += self._parse_items(cafe, "cafe")

        terms = self._make_relevance_terms(core, laws_pack)

        scored = []
        for x in items:
            rel = self._relevance_score(x["title"], x["desc"], terms)
            pro = self._professional_score(x["title"], x["desc"], x["link"]) if x["source"] in ("blog", "cafe") else 0
            x2 = dict(x)
            x2["rel_score"] = rel
            x2["pro_score"] = pro
            scored.append(x2)

        filtered = []
        for x in scored:
            src = x["source"]
            if src in ("news", "webkr"):
                if x["rel_score"] >= 6:
                    filtered.append(x)
            else:
                if x["pro_score"] >= 6 and x["rel_score"] >= 6:
                    filtered.append(x)

        # âœ… (ì„ íƒ) LLM ì •ë°€ ë¦¬ë­í‚¹: ê´€ë ¨=1 / ë¬´ê´€=0
        if enable_llm_rerank and llm:
            keep = []
            for x in filtered[:12]:
                p = f"""
ì•„ë˜ ê²€ìƒ‰ê²°ê³¼ê°€ 'ë¯¼ì› ìƒí™©'ê³¼ ì§ì ‘ ê´€ë ¨ì´ ìˆìœ¼ë©´ 1, ì•„ë‹ˆë©´ 0ë§Œ ì¶œë ¥.
ì¸ì‚¿ë§ ê¸ˆì§€, ì„¤ëª… ê¸ˆì§€.
ë¯¼ì›: {core}
ê²€ìƒ‰ê²°ê³¼: {x['title']} / {x['desc']}
"""
                ans = (llm.generate_text(p) or "").strip()
                if ans.startswith("1"):
                    keep.append(x)
            filtered = keep

        filtered.sort(key=lambda z: (z.get("rel_score", 0) + (z.get("pro_score", 0) * 0.3)), reverse=True)

        # ì†ŒìŠ¤ë³„ ìƒí•œ(ì ë¦¼ ë°©ì§€)
        out = []
        caps = {"news": 5, "webkr": 5, "blog": 3, "cafe": 3}
        cnt = {k: 0 for k in caps}
        for x in filtered:
            s = x["source"]
            if s in caps and cnt[s] >= caps[s]:
                continue
            cnt[s] += 1
            out.append(x)

        return out


class DatabaseService:
    """
    secrets:
      [supabase]
      SUPABASE_URL
      SUPABASE_KEY
    """
    def __init__(self, trace: Trace):
        self.trace = trace
        self.is_active = False
        self.client = None

        if create_client is None:
            self.trace.add("Supabase.init", False, "supabase lib missing")
            return

        s = st.secrets.get("supabase", {})
        url = s.get("SUPABASE_URL")
        key = s.get("SUPABASE_KEY")
        if not url or not key:
            self.trace.add("Supabase.init", False, "URL/KEY missing")
            return
        try:
            self.client = create_client(url, key)
            self.is_active = True
            self.trace.add("Supabase.init", True, "connected")
        except Exception as e:
            self.trace.add("Supabase.init", False, f"{type(e).__name__}: {e}")

    def save_log(self, table: str, payload: dict):
        if not self.is_active or not self.client:
            return "DB ë¯¸ì—°ê²° (ì €ì¥ ê±´ë„ˆëœ€)"
        try:
            self.client.table(table).insert(payload).execute()
            self.trace.add("Supabase.insert", True, f"table={table}")
            return "DB ì €ì¥ ì„±ê³µ"
        except Exception as e:
            self.trace.add("Supabase.insert", False, f"{type(e).__name__}: {e}")
            return f"DB ì €ì¥ ì‹¤íŒ¨: {e}"


# =========================================================
# 5) Agents
# =========================================================
class LegalAgents:
    @staticmethod
    def strategist(llm: LLMService, situation: str, laws_pack: dict, precedent_items: list[dict]):
        legal_basis = laws_pack.get("legal_basis_text", "")
        related = laws_pack.get("related", []) or []
        primary = laws_pack.get("primary", {}) or {}

        rel_lines = []
        for i, it in enumerate(related[:3], 1):
            nm = it.get("law_name", "")
            ar = it.get("article", "")
            jo6 = it.get("jo6")
            mst = it.get("mst")
            rel_lines.append(f"{i}) {nm} {ar} (MST={mst}, JO={jo6})")
        rel_block = "\n".join(rel_lines) if rel_lines else "(ì—†ìŒ)"

        brief = []
        for it in (precedent_items or [])[:8]:
            src = it.get("source")
            title = it.get("title")
            desc = it.get("desc")
            brief.append(f"- [{src}] {title}: {desc}")
        brief_block = "\n".join(brief) if brief else "(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"

        prompt = f"""
ë„ˆëŠ” í–‰ì • ì‹¤ë¬´ 'ì£¼ë¬´ê´€'ì´ë‹¤.

[ì¶œë ¥ ì œì•½]
- ì¸ì‚¿ë§/ìê¸°ì†Œê°œ/ê°ì‚¬ ë¬¸êµ¬ ê¸ˆì§€. ë°”ë¡œ ë³¸ë¬¸ ì‹œì‘.
- ê³¼ë„í•œ ì¼ë°˜ë¡  ê¸ˆì§€. ë³¸ ë¯¼ì›ê³¼ ë²•ë ¹ì— ì§ì ‘ ì—°ê²°ëœ ë¬¸ì¥ë§Œ.
- ì•„ë˜ 3ê°œ í•­ëª©ë§Œ, ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ.

[ë¯¼ì› ìƒí™©]
{situation}

[ëŒ€í‘œ ê·¼ê±°]
{legal_basis}

[ëŒ€í‘œ MST/JO]
MST={primary.get("mst")} / JO={primary.get("jo6")}

[ì—°ê´€ ë²•ë ¹ 3ê°œ]
{rel_block}

[ìœ ì‚¬ ì‚¬ë¡€(ë„¤ì´ë²„: ë‰´ìŠ¤/ì›¹ + ì „ë¬¸ ë¸”ë¡œê·¸/ì¹´í˜ë§Œ + ê´€ë ¨ì„± í•„í„°)]
{brief_block}

1. **ì²˜ë¦¬ ë°©í–¥**
2. **í•µì‹¬ ì£¼ì˜ì‚¬í•­**
3. **ì˜ˆìƒ ë°˜ë°œ ë° ëŒ€ì‘**
"""
        return llm.generate_text(prompt)

    @staticmethod
    def clerk(llm: LLMService, situation: str, legal_basis: str):
        today = datetime.now()
        prompt = f"""
ì˜¤ëŠ˜: {today.strftime('%Y-%m-%d')}
ìƒí™©: {situation}
ë²•ë ¹(ëŒ€í‘œ): {legal_basis}

í–‰ì •ì²˜ë¶„ ì‚¬ì „í†µì§€/ì´í–‰ëª…ë ¹ ì‹œ í†µìƒ ë¶€ì—¬í•˜ëŠ”
'ì´í–‰/ì˜ê²¬ì œì¶œ ê¸°ê°„'ì„ ì¼ìˆ˜ ìˆ«ìë§Œ ì¶œë ¥.
ëª¨ë¥´ë©´ 15.
"""
        days = 15
        try:
            res = llm.generate_text(prompt)
            days = int(re.sub(r"[^0-9]", "", res) or "15")
            if days <= 0:
                days = 15
        except Exception:
            days = 15

        deadline = today + timedelta(days=days)
        return {
            "today_str": today.strftime("%Y. %m. %d."),
            "deadline_str": deadline.strftime("%Y. %m. %d."),
            "days_added": days,
            "doc_num": f"í–‰ì •-{today.strftime('%Y')}-{int(time.time())%1000:03d}í˜¸",
        }

    @staticmethod
    def drafter(llm: LLMService, situation: str, laws_pack: dict, meta_info: dict, strategy: str):
        situation = mask_pii(situation)
        primary = laws_pack.get("primary", {}) or {}
        related = laws_pack.get("related", []) or []

        rel_bullets = []
        for it in related[:3]:
            nm = it.get("law_name", "")
            ar = it.get("article", "")
            if nm:
                rel_bullets.append(f"- {nm} {ar}".strip())
        rel_text = "\n".join(rel_bullets) if rel_bullets else "- (ì—°ê´€ ë²•ë ¹ í™•ì¸ ë¶ˆê°€)"

        prompt = f"""
ë„ˆëŠ” í–‰ì •ê¸°ê´€ì˜ ì„œê¸°ë‹¤. ì•„ë˜ ì •ë³´ë¡œ ì™„ê²°ëœ ê³µë¬¸ì„œë¥¼ JSONìœ¼ë¡œ ì‘ì„±í•´ë¼.

ë°˜ë“œì‹œ JSONë§Œ:
{{
  "title": "ë¬¸ì„œ ì œëª©",
  "receiver": "ìˆ˜ì‹ ",
  "body_paragraphs": ["ë¬¸ë‹¨1", "ë¬¸ë‹¨2", "ë¬¸ë‹¨3"],
  "department_head": "ë°œì‹  ëª…ì˜"
}}

[ì…ë ¥]
- ë¯¼ì› ìƒí™©: {situation}
- ëŒ€í‘œ ê·¼ê±°: {laws_pack.get("legal_basis_text","")}
- ëŒ€í‘œ ë²•ë ¹ MST/JO: MST={primary.get("mst")} / JO={primary.get("jo6")} (JOëŠ” 6ìë¦¬)
- ëŒ€í‘œ ì¡°ë¬¸ ë‚´ìš©(ê°€ëŠ¥í•˜ë©´): {primary.get("article_text","")}
- ì—°ê´€ ë²•ë ¹(ìµœëŒ€ 3ê°œ):
{rel_text}
- ì‹œí–‰ ì¼ì: {meta_info['today_str']}
- ê¸°í•œ: {meta_info['deadline_str']} ({meta_info['days_added']}ì¼)

[ì „ëµ]
{strategy}

[ì‘ì„± ì›ì¹™]
- ë³¸ë¬¸ êµ¬ì¡°: [ê²½ìœ„] -> [ê·¼ê±°] -> [ì²˜ë¶„ ë‚´ìš©] -> [ê¶Œë¦¬êµ¬ì œ ì ˆì°¨]
- ê°œì¸ì •ë³´ëŠ” 'OOO'ë¡œ ë§ˆìŠ¤í‚¹
- í–‰ì •ë¬¸ì„œ í†¤: ê±´ì¡°/ì •ì¤‘
"""
        doc = llm.generate_json(prompt)

        if not isinstance(doc, dict):
            doc = {
                "title": "ê³µ ë¬¸ ì„œ",
                "receiver": "ìˆ˜ì‹ ì ì°¸ì¡°",
                "body_paragraphs": [
                    "1. ê·€í•˜ì˜ ë¯¼ì›ì— ëŒ€í•˜ì—¬ ì•„ë˜ì™€ ê°™ì´ ê²€í†  ê²°ê³¼ë¥¼ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.",
                    f"2. ê´€ë ¨ ê·¼ê±°(ëŒ€í‘œ): {laws_pack.get('legal_basis_text','')}",
                    "3. ì—°ê´€ ë²•ë ¹(ì°¸ê³ ):\n" + rel_text,
                    f"4. (ì˜ê²¬ì œì¶œ/ì´í–‰) ê¸°í•œ: {meta_info['deadline_str']}ê¹Œì§€",
                    "5. ê¸°íƒ€ ë¬¸ì˜ëŠ” ë‹´ë‹¹ë¶€ì„œë¡œ ì—°ë½ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.",
                ],
                "department_head": "í–‰ì •ê¸°ê´€ì¥",
            }

        doc.setdefault("title", "ê³µ ë¬¸ ì„œ")
        doc.setdefault("receiver", "ìˆ˜ì‹ ì ì°¸ì¡°")
        doc.setdefault("body_paragraphs", [])
        doc.setdefault("department_head", "í–‰ì •ê¸°ê´€ì¥")
        if isinstance(doc["body_paragraphs"], str):
            doc["body_paragraphs"] = [doc["body_paragraphs"]]

        return doc


# =========================================================
# 6) Rendering helpers
# =========================================================
def render_api_trace(trace_items):
    if not trace_items:
        st.info("API ì‚¬ìš© ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    pills = []
    for it in trace_items:
        cls = "api-pill api-ok" if it.get("ok") else "api-pill api-bad"
        name = escape(str(it.get("name", "")))
        detail = escape(str(it.get("detail", "")))
        tok = it.get("tokens")
        tok_str = ""
        if isinstance(tok, dict):
            tok_str = f" | tokens p={tok.get('prompt')}, o={tok.get('output')}, t={tok.get('total')}"
        pills.append(f"<span class='{cls}' title='{detail}{tok_str}'>{name}</span>")
    st.markdown(
        f"<div class='api-box'>{''.join(pills)}<div class='small-muted'>*pill hover/ê¸¸ê²ŒëˆŒëŸ¬ ìƒì„¸(í† í° í¬í•¨)</div></div>",
        unsafe_allow_html=True,
    )


def render_usage_summary(usage: dict):
    calls = (usage or {}).get("calls", {}) or {}
    tokens = (usage or {}).get("tokens", {}) or {}

    st.markdown("#### ğŸ“ API í˜¸ì¶œ ìˆ˜")
    if calls:
        rows = [{"API": k, "Calls": v} for k, v in sorted(calls.items(), key=lambda x: (-x[1], x[0]))]
        st.dataframe(rows, use_container_width=True, hide_index=True)
    else:
        st.info("í˜¸ì¶œ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("#### ğŸ§¾ í† í° ì‚¬ìš©ëŸ‰(ê°€ëŠ¥í•œ ë²”ìœ„)")
    t_rows = [
        {"Provider": "Gemini", "Prompt": tokens.get("gemini_prompt", 0), "Output": tokens.get("gemini_output", 0), "Total": tokens.get("gemini_total", 0)},
        {"Provider": "Groq", "Prompt": tokens.get("groq_prompt", 0), "Output": tokens.get("groq_output", 0), "Total": tokens.get("groq_total", 0)},
    ]
    st.dataframe(t_rows, use_container_width=True, hide_index=True)
    st.caption("â€» Gemini í† í°ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬/ì‘ë‹µ ë²„ì „ì— ë”°ë¼ ë¯¸ì œê³µ(None)ì¼ ìˆ˜ ìˆìœ¼ë©°, ì œê³µë  ë•Œë§Œ í•©ì‚°ë©ë‹ˆë‹¤.")


def law_link_from_meta(link: str, mst: str | None, jo6: str | None, oc: str | None) -> str:
    link = safe_url(link)
    if link:
        return link
    if not (mst and oc):
        return ""
    base = f"https://www.law.go.kr/DRF/lawService.do?OC={oc}&target=law&MST={mst}&type=HTML"
    if jo6:
        base += f"&JO={jo6}"
    return base


def render_laws_pack(laws_pack: dict):
    related = laws_pack.get("related", []) or []
    if not related:
        st.warning("ë²•ë ¹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    g = st.secrets.get("general", {})
    oc = g.get("LAW_API_ID")

    st.markdown("**ğŸ“œ ëŒ€í‘œ + ì—°ê´€ ë²•ë ¹ (ìµœëŒ€ 3ê°œ)**")
    for idx, it in enumerate(related[:3], 1):
        nm = it.get("law_name", "")
        ar = it.get("article", "")
        mst = it.get("mst")
        jo6 = it.get("jo6")
        link = it.get("link", "")

        full_url = law_link_from_meta(link, mst, jo6, oc)

        if full_url:
            st.markdown(f"### {idx}) [{escape(nm)} {escape(ar)}]({full_url})")
            st.link_button(f"ğŸ”— ì›ë¬¸ ë³´ê¸° - {idx}", full_url, use_container_width=True)
        else:
            st.markdown(f"### {idx}) {escape(nm)} {escape(ar)}")

        st.caption(f"MST: {mst} | JO(6ìë¦¬): {jo6}")

        art = (it.get("article_text") or "").strip()
        if art:
            with st.expander(f"ì¡°ë¬¸ ë‚´ìš©(ê°€ëŠ¥í•œ ê²½ìš°) - {idx}", expanded=False):
                st.info(art)
        else:
            st.caption("ì¡°ë¬¸ ë‚´ìš©ì€ JO/MST ë§¤ì¹­ì´ ë¶ˆì™„ì „í•˜ë©´ ë¹„ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


def render_precedents(items: list[dict]):
    if not items:
        st.info("ê´€ë ¨ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    def src_label(src: str) -> str:
        return {
            "news": "ë‰´ìŠ¤",
            "webkr": "ì›¹ë¬¸ì„œ",
            "blog": "ë¸”ë¡œê·¸(ì „ë¬¸+ê´€ë ¨ í•„í„°)",
            "cafe": "ì¹´í˜(ì „ë¬¸+ê´€ë ¨ í•„í„°)",
        }.get(src, src or "ê²€ìƒ‰")

    for it in items[:16]:
        src = it.get("source", "")
        title = it.get("title", "")
        desc = it.get("desc", "")
        link = safe_url(it.get("link", "") or "")
        rel = it.get("rel_score", None)
        pro = it.get("pro_score", None)

        st.markdown("<div class='item-card'>", unsafe_allow_html=True)
        st.markdown(f"<div class='item-title'>[{escape(src_label(src))}] {escape(title)}</div>", unsafe_allow_html=True)

        meta = []
        if isinstance(rel, int):
            meta.append(f"rel={rel}")
        if isinstance(pro, int) and src in ("blog", "cafe"):
            meta.append(f"pro={pro}")
        if meta:
            st.markdown(f"<div class='item-meta'>{escape(' | '.join(meta))}</div>", unsafe_allow_html=True)

        st.markdown(f"<div class='item-desc'>{escape(desc)}</div>", unsafe_allow_html=True)
        if link:
            st.link_button("ì—´ê¸°", link, use_container_width=True)
        st.markdown("</div>", unsafe_allow_html=True)


# =========================================================
# 7) Workflow
# =========================================================
def run_workflow(user_input: str, enable_llm_rerank: bool):
    trace = Trace()
    llm = LLMService(trace)
    law_api = LawAPIService(trace)
    naver = NaverSearchService(trace)
    db = DatabaseService(trace)

    log_placeholder = st.empty()
    logs = []

    def add_log(msg, style="sys"):
        logs.append(f"<div class='agent-log log-{style}'>{escape(msg)}</div>")
        log_placeholder.markdown("".join(logs), unsafe_allow_html=True)
        time.sleep(0.12)

    add_log("ğŸ” Phase 1: ë²•ë ¹ API(ë²•ì œì²˜)ë¡œ ëŒ€í‘œ+ì—°ê´€ ë²•ë ¹ 3ê°œ ì°¾ëŠ” ì¤‘...", "legal")
    laws_pack = law_api.get_related_laws_pack(user_input, llm, topk=3)
    add_log(f"ğŸ“œ ëŒ€í‘œ ê·¼ê±°: {laws_pack.get('legal_basis_text','')}", "legal")

    add_log("ğŸ” Phase 1b: ë„¤ì´ë²„ ê²€ìƒ‰(ë‰´ìŠ¤/ì›¹/ë¸”ë¡œê·¸/ì¹´í˜) + ê´€ë ¨ì„±/ì „ë¬¸ì„± í•„í„°...", "search")
    precedent_items = naver.search_precedents_parsed(
        user_input,
        laws_pack,
        enable_llm_rerank=enable_llm_rerank,
        llm=llm if enable_llm_rerank else None
    )

    add_log("ğŸ§  Phase 2: ì—…ë¬´ ì²˜ë¦¬ ë°©í–¥ ìˆ˜ë¦½ ì¤‘...", "strat")
    strategy = LegalAgents.strategist(llm, user_input, laws_pack, precedent_items)

    add_log("ğŸ“… Phase 3: ê¸°í•œ ì‚°ì • ì¤‘...", "calc")
    meta_info = LegalAgents.clerk(llm, user_input, laws_pack.get("legal_basis_text", ""))

    add_log("âœï¸ Phase 3b: ê³µë¬¸ì„œ ì‘ì„± ì¤‘...", "draft")
    doc_data = LegalAgents.drafter(llm, user_input, laws_pack, meta_info, strategy)

    add_log("ğŸ’¾ Phase 4: Supabase ì €ì¥ ì‹œë„...", "sys")
    payload = {
        "situation": mask_pii(user_input),
        "law_name": laws_pack.get("legal_basis_text", ""),
        "summary": json.dumps(
            {
                "laws_pack": laws_pack,
                "precedent_items": precedent_items,
                "strategy": strategy,
                "document_content": doc_data,
                "api_trace": trace.items,
                "usage_summary": trace.usage_summary(),
                "rerank_enabled": bool(enable_llm_rerank),
            },
            ensure_ascii=False,
        ),
    }
    save_msg = db.save_log("law_reports", payload)

    add_log(f"âœ… ì™„ë£Œ: {save_msg}", "sys")
    time.sleep(0.35)
    log_placeholder.empty()

    return {
        "doc": doc_data,
        "meta": meta_info,
        "laws_pack": laws_pack,
        "precedent_items": precedent_items,
        "strategy": strategy,
        "save_msg": save_msg,
        "api_trace": trace.items,
        "api_trace_md": trace.to_markdown(),
        "usage_summary": trace.usage_summary(),
        "rerank_enabled": bool(enable_llm_rerank),
    }


# =========================================================
# 8) UI
# =========================================================
def main():
    col_left, col_right = st.columns([1, 1.2])

    with col_left:
        st.title("ğŸ¢ AI í–‰ì •ê´€ Pro")
        st.caption("LAWGO(ë²•ì œì²˜ DRF) + NAVER(ë‰´ìŠ¤/ì›¹/ì „ë¬¸ ë¸”ë¡œê·¸Â·ì¹´í˜) + Geminiâ†’Groq + Supabase")
        st.markdown("---")

        st.markdown("### ğŸ—£ï¸ ì—…ë¬´ ì§€ì‹œ")
        user_input = st.text_area(
            "ì—…ë¬´ ë‚´ìš©",
            height=150,
            placeholder="ì˜ˆì‹œ:\n- ì†Œë°©ì°¨ ì „ìš©êµ¬ì—­ ë¶ˆë²•ì£¼ì°¨ ê³¼íƒœë£Œ ì•ˆë‚´ë¬¸ ì‘ì„±\n- ë¬´ë‹¨ë°©ì¹˜ì°¨ëŸ‰ ê°•ì œì²˜ë¦¬ ì ˆì°¨ ì•ˆë‚´ ê³µë¬¸ ì‘ì„±",
            label_visibility="collapsed",
        )

        enable_llm_rerank = st.toggle(
            "ì •ë°€ ë¦¬ë­í‚¹(LLMë¡œ ê²€ìƒ‰ê²°ê³¼ ê´€ë ¨/ë¬´ê´€ í•„í„°ë§) â€” ì •í™•ë„â†‘ ë¹„ìš©â†‘",
            value=False
        )

        if st.button("âš¡ ìŠ¤ë§ˆíŠ¸ í–‰ì • ì²˜ë¶„ ì‹œì‘", type="primary", use_container_width=True):
            if not user_input.strip():
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                try:
                    with st.spinner("AI ì—ì´ì „íŠ¸ íŒ€ì´ í˜‘ì—… ì¤‘ì…ë‹ˆë‹¤..."):
                        st.session_state["workflow_result"] = run_workflow(user_input.strip(), enable_llm_rerank)
                except Exception as e:
                    st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {e}")

        if "workflow_result" in st.session_state:
            res = st.session_state["workflow_result"]
            st.markdown("---")

            if "ì„±ê³µ" in (res.get("save_msg") or ""):
                st.success(f"âœ… {res.get('save_msg')}")
            else:
                st.warning(res.get("save_msg", "DB ë¯¸ì—°ê²°"))

            with st.expander("ğŸ“Š [í‘œì‹œ] í˜¸ì¶œ ìˆ˜ / í† í° ì‚¬ìš©ëŸ‰", expanded=True):
                render_usage_summary(res.get("usage_summary", {}))

            with st.expander("ğŸ”Œ [í‘œì‹œ] ì´ë²ˆ ì—…ë¬´ì—ì„œ ì‚¬ìš©í•œ API (ìƒì„¸)", expanded=False):
                render_api_trace(res.get("api_trace", []))
                st.markdown(res.get("api_trace_md", ""))

            with st.expander("âœ… [ê²€í† ] ë²•ë ¹(ë²•ì œì²˜ API) â€” ì œëª© í´ë¦­=ì›ë¬¸ ë³´ê¸°", expanded=True):
                render_laws_pack(res.get("laws_pack", {}))

            with st.expander("ğŸ” [ê²€í† ] ìœ ì‚¬ ì‚¬ë¡€(ë„¤ì´ë²„) â€” ê´€ë ¨ì„±/ì „ë¬¸ì„± í•„í„° ì ìš©", expanded=True):
                st.caption(f"ì •ë°€ ë¦¬ë­í‚¹: {'ON' if res.get('rerank_enabled') else 'OFF'}")
                render_precedents(res.get("precedent_items", []))

            with st.expander("ğŸ§­ [ë°©í–¥] ì—…ë¬´ ì²˜ë¦¬ ê°€ì´ë“œë¼ì¸", expanded=True):
                st.markdown(res.get("strategy", ""))

    with col_right:
        if "workflow_result" in st.session_state:
            res = st.session_state["workflow_result"]
            doc = res.get("doc") or {}
            meta = res.get("meta") or {}

            paragraphs = doc.get("body_paragraphs", [])
            if isinstance(paragraphs, str):
                paragraphs = [paragraphs]

            html_content = f"""
<div class="paper-sheet">
  <div class="stamp">ì§ì¸ìƒëµ</div>
  <div class="doc-header">{escape(doc.get('title', 'ê³µ ë¬¸ ì„œ'))}</div>
  <div class="doc-info">
    <span>ë¬¸ì„œë²ˆí˜¸: {escape(str(meta.get('doc_num','')))}</span>
    <span>ì‹œí–‰ì¼ì: {escape(str(meta.get('today_str','')))}</span>
    <span>ìˆ˜ì‹ : {escape(doc.get('receiver', 'ìˆ˜ì‹ ì ì°¸ì¡°'))}</span>
  </div>
  <hr style="border: 1px solid black; margin-bottom: 30px;">
  <div class="doc-body">
"""
            for p in paragraphs:
                html_content += f"<p style='margin-bottom: 15px;'>{escape(str(p))}</p>"

            html_content += f"""
  </div>
  <div class="doc-footer">{escape(doc.get('department_head', 'í–‰ì •ê¸°ê´€ì¥'))}</div>
</div>
"""
            st.markdown(html_content, unsafe_allow_html=True)
        else:
            st.markdown(
                """
<div style='text-align: center; padding: 100px; color: #aaa; background: white; border-radius: 10px; border: 2px dashed #ddd;'>
  <h3>ğŸ“„ Document Preview</h3>
  <p>ì™¼ìª½ì—ì„œ ì—…ë¬´ë¥¼ ì§€ì‹œí•˜ë©´<br>ì™„ì„±ëœ ê³µë¬¸ì„œê°€ ì—¬ê¸°ì— ë‚˜íƒ€ë‚©ë‹ˆë‹¤.</p>
</div>
""",
                unsafe_allow_html=True,
            )


if __name__ == "__main__":
    main()
