# -*- coding: utf-8 -*-
"""
Govable AI - ê´€ë¦¬ìž ëŒ€ì‹œë³´ë“œ UI

ì´ ëª¨ë“ˆì—ì„œë§Œ streamlit import í—ˆìš©
"""
from datetime import datetime, timedelta
from typing import TYPE_CHECKING

import streamlit as st

from govable_ai.config import MODEL_PRICING, HEAVY_USER_PERCENTILE, LONG_LATENCY_THRESHOLD

if TYPE_CHECKING:
    from govable_ai.core.db_client import SupabaseClient

# Pandas optional import
try:
    import pandas as pd
except ImportError:
    pd = None


def render_master_dashboard(db_client: "SupabaseClient", llm_service=None) -> None:
    """
    ê´€ë¦¬ìž ë§ˆìŠ¤í„° ëŒ€ì‹œë³´ë“œ ë Œë”ë§
    
    Args:
        db_client: Supabase DB í´ë¼ì´ì–¸íŠ¸
        llm_service: ìž„ë² ë”© ìƒì„±ì„ ìœ„í•œ LLM ì„œë¹„ìŠ¤ (Optional)
    """
    if pd is None:
        st.error("pandasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `pip install pandas` ì‹¤í–‰ í•„ìš”")
        return
    
    if not db_client or not db_client.is_available():
        st.error("DB ì—°ê²° ì—†ìŒ")
        return
    
    st.markdown("## ðŸ“Š ë§ˆìŠ¤í„° ëŒ€ì‹œë³´ë“œ")
    
    # [NEW] ë°ì´í„° ê´€ë¦¬ (ìž„ë² ë”© ìƒì„±)
    with st.expander("ðŸ› ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ (ìž„ë² ë”© ìƒì„±)", expanded=False):
        st.info("ë‹¹ì§ ë§¤ë‰´ì–¼ ë°ì´í„°ì— ë²¡í„° ìž„ë² ë”©ì´ ì—†ëŠ” ê²½ìš° ê²€ìƒ‰ì´ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì•„ëž˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìž„ë² ë”©ì„ ìƒì„±í•˜ì„¸ìš”.")
        
        col_db1, col_db2 = st.columns(2)
        with col_db1:
            if st.button("ðŸ”„ ë§¤ë‰´ì–¼ ìž„ë² ë”© ìƒì„±(ìž¬ì²˜ë¦¬)", use_container_width=True):
                if not llm_service:
                    st.error("LLM ì„œë¹„ìŠ¤ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    try:
                        # 1. ìž„ë² ë”© ì—†ëŠ” ë°ì´í„° ì¡°íšŒ
                        res = db_client.client.table("duty_manual_kb").select("*").is_("embedding", "null").execute()
                        rows = res.data
                        
                        if not rows:
                            st.success("ëª¨ë“  ë°ì´í„°ì— ìž„ë² ë”©ì´ ì´ë¯¸ ì¡´ìž¬í•©ë‹ˆë‹¤.")
                        else:
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            success_count = 0
                            
                            for idx, row in enumerate(rows):
                                content = row.get("content", "")
                                if content:
                                    emb = llm_service.embed_text(content)
                                    if emb:
                                        # ì—…ë°ì´íŠ¸
                                        db_client.client.table("duty_manual_kb").update({"embedding": emb}).eq("id", row["id"]).execute()
                                        success_count += 1
                                
                                progress = (idx + 1) / len(rows)
                                progress_bar.progress(progress)
                                status_text.text(f"ì²˜ë¦¬ ì¤‘... ({idx+1}/{len(rows)})")
                            
                            st.success(f"ì™„ë£Œ! {success_count}ê±´ì˜ ìž„ë² ë”©ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                            st.rerun()
                            
                    except Exception as e:
                        st.error(f"ìž‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ë°ì´í„° ë¡œë“œ
    with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
        archives = db_client.admin_fetch_work_archive(limit=2000)
        sessions = db_client.admin_fetch_sessions(minutes=5)
        events = db_client.admin_fetch_events(limit=300)
        api_logs = db_client.admin_fetch_api_logs(limit=500)
    
    # ì‹¤ì‹œê°„ í˜„í™©
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ðŸŸ¢ ì‹¤ì‹œê°„ ì ‘ì†", len(sessions))
    with col2:
        st.metric("ðŸ“ ì „ì²´ ìž‘ì—…", len(archives))
    with col3:
        st.metric("ðŸ“Š ì´ë²¤íŠ¸ ìˆ˜", len(events))
    with col4:
        st.metric("ðŸ”Œ API í˜¸ì¶œ", len(api_logs))
    
    st.markdown("---")
    
    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4 = st.tabs(["ðŸ“ˆ ì¢…í•© í†µê³„", "ðŸ‘¥ ì‚¬ìš©ìž ë¶„ì„", "ðŸ’° ë¹„ìš© ë¶„ì„", "ðŸ“œ ìƒì„¸ ë¡œê·¸"])
    
    with tab1:
        _render_summary_stats(archives, api_logs)
    
    with tab2:
        _render_user_analysis(archives, events)
    
    with tab3:
        _render_cost_analysis(api_logs)
    
    with tab4:
        _render_detailed_logs(archives, api_logs)


def _render_summary_stats(archives: list, api_logs: list) -> None:
    """ì¢…í•© í†µê³„ ë Œë”ë§"""
    if not archives:
        st.info("ë°ì´í„° ì—†ìŒ")
        return
    
    df = pd.DataFrame(archives)
    
    if "created_at" in df.columns:
        df["created_at"] = pd.to_datetime(df["created_at"])
        df["date"] = df["created_at"].dt.date
        
        # ì¼ë³„ ìž‘ì—… ìˆ˜ ì°¨íŠ¸
        st.markdown("### ðŸ“… ì¼ë³„ ìž‘ì—… í˜„í™©")
        daily = df.groupby("date").size().reset_index(name="count")
        st.bar_chart(daily.set_index("date")["count"])
    
    # ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰
    if "model_used" in df.columns:
        st.markdown("### ðŸ¤– ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰")
        model_counts = df["model_used"].value_counts()
        st.bar_chart(model_counts)
    
    # ì•± ëª¨ë“œë³„ ì‚¬ìš©ëŸ‰
    if "app_mode" in df.columns:
        st.markdown("### âš¡ ì²˜ë¦¬ ëª¨ë“œë³„ ë¶„í¬")
        mode_counts = df["app_mode"].value_counts()
        st.bar_chart(mode_counts)


def _render_user_analysis(archives: list, events: list) -> None:
    """ì‚¬ìš©ìž ë¶„ì„ ë Œë”ë§"""
    if not archives:
        st.info("ë°ì´í„° ì—†ìŒ")
        return
    
    df = pd.DataFrame(archives)
    
    # ì‚¬ìš©ìžë³„ ìž‘ì—… ìˆ˜
    if "user_email" in df.columns:
        st.markdown("### ðŸ‘¤ ì‚¬ìš©ìžë³„ ìž‘ì—… ìˆ˜ (Top 20)")
        
        # null ì œì™¸
        user_df = df[df["user_email"].notna()]
        if not user_df.empty:
            user_counts = user_df["user_email"].value_counts().head(20)
            
            # ê³¼ë‹¤ ì‚¬ìš©ìž ìž„ê³„ê°’ ê³„ì‚°
            threshold = user_counts.quantile(HEAVY_USER_PERCENTILE / 100) if len(user_counts) > 5 else float("inf")
            
            for email, count in user_counts.items():
                flag = "ðŸ”´ " if count >= threshold else ""
                st.markdown(f"- {flag}**{email}**: {count}ê±´")
        else:
            st.caption("ë¡œê·¸ì¸ ì‚¬ìš©ìž ì—†ìŒ")
    
    # ìµëª… ì„¸ì…˜ ë¶„ì„
    if "anon_session_id" in df.columns:
        st.markdown("### ðŸ”’ ìµëª… ì„¸ì…˜ ë¶„ì„")
        anon_counts = df["anon_session_id"].nunique()
        st.metric("ê³ ìœ  ì„¸ì…˜ ìˆ˜", anon_counts)


def _render_cost_analysis(api_logs: list) -> None:
    """ë¹„ìš© ë¶„ì„ ë Œë”ë§"""
    if not api_logs:
        st.info("API í˜¸ì¶œ ë¡œê·¸ ì—†ìŒ")
        return
    
    df = pd.DataFrame(api_logs)
    
    # ë¹„ìš© ê³„ì‚°
    def calc_cost(row):
        model = row.get("model_name", "")
        tokens = (row.get("input_tokens", 0) or 0) + (row.get("output_tokens", 0) or 0)
        price = MODEL_PRICING.get(model, MODEL_PRICING.get("(unknown)", 0.10))
        return (tokens / 1_000_000) * price
    
    df["cost_usd"] = df.apply(calc_cost, axis=1)
    
    # ì´ ë¹„ìš©
    total_cost = df["cost_usd"].sum()
    st.metric("ðŸ’° ì´ ëˆ„ì  ë¹„ìš© (ì¶”ì •)", f"${total_cost:.4f}")
    
    # API ìœ í˜•ë³„ ë¹„ìš©
    if "api_type" in df.columns:
        st.markdown("### ðŸ“Š API ìœ í˜•ë³„ ë¹„ìš©")
        api_cost = df.groupby("api_type")["cost_usd"].sum().sort_values(ascending=False)
        st.bar_chart(api_cost)
    
    # ëª¨ë¸ë³„ ë¹„ìš©
    if "model_name" in df.columns:
        st.markdown("### ðŸ¤– ëª¨ë¸ë³„ ë¹„ìš©")
        model_cost = df.groupby("model_name")["cost_usd"].sum().sort_values(ascending=False)
        for model, cost in model_cost.items():
            if model and cost > 0:
                st.markdown(f"- **{model}**: ${cost:.4f}")
    
    # í† í° ì‚¬ìš©ëŸ‰
    total_tokens = (df["input_tokens"].fillna(0).sum() + df["output_tokens"].fillna(0).sum())
    st.metric("ðŸ“ ì´ í† í° ì‚¬ìš©ëŸ‰", f"{int(total_tokens):,}")


def _render_detailed_logs(archives: list, api_logs: list) -> None:
    """ìƒì„¸ ë¡œê·¸ ë Œë”ë§"""
    st.markdown("### ðŸ“œ ìµœê·¼ ìž‘ì—… ë¡œê·¸")
    
    if archives:
        df = pd.DataFrame(archives)
        
        # ì»¬ëŸ¼ ì„ íƒ
        display_cols = ["created_at", "user_email", "prompt", "model_used", "execution_time", "token_usage"]
        display_cols = [c for c in display_cols if c in df.columns]
        
        if display_cols:
            # í”„ë¡¬í”„íŠ¸ ìš”ì•½
            if "prompt" in df.columns:
                df["prompt"] = df["prompt"].apply(lambda x: (x[:50] + "...") if x and len(x) > 50 else x)
            
            # ê¸´ ë ˆì´í„´ì‹œ í•˜ì´ë¼ì´íŒ…
            def highlight_rows(row):
                styles = [""] * len(row)
                if "execution_time" in row.index:
                    exec_time = row.get("execution_time", 0) or 0
                    if exec_time > LONG_LATENCY_THRESHOLD:
                        styles = ["background-color: #ffebee"] * len(row)
                return styles
            
            styled_df = df[display_cols].head(50).style.apply(highlight_rows, axis=1)
            st.dataframe(styled_df, use_container_width=True)
    
    st.markdown("### ðŸ”Œ ìµœê·¼ API í˜¸ì¶œ ë¡œê·¸")
    
    if api_logs:
        df = pd.DataFrame(api_logs)
        
        display_cols = ["created_at", "api_type", "model_name", "input_tokens", "output_tokens", "latency_ms", "success"]
        display_cols = [c for c in display_cols if c in df.columns]
        
        if display_cols:
            st.dataframe(df[display_cols].head(50), use_container_width=True)
