# hallucination_detection.py
# AI í™˜ê° íƒì§€ ë° ì—…ë¬´ íš¨ìœ¨í™” ëª¨ë“ˆ
# -*- coding: utf-8 -*-

"""
AI-generated petition hallucination detection module.

This module provides tools to detect hallucinations (false information) in 
AI-generated petitions and streamline civil servant workflows.

Optional dependencies are handled gracefully to ensure the app boots even
if some packages are missing (e.g., in Streamlit Cloud deployments).
"""

import re
import json
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

# Core dependencies (always required)
import streamlit as st

# Optional dependencies - handle gracefully
try:
    from datetime import timedelta
except ImportError:
    timedelta = None
    print("Warning: datetime.timedelta not available - some features may be limited")

# =========================================================
# 1) í™˜ê° íƒì§€ í•µì‹¬ í•¨ìˆ˜
# =========================================================

def detect_hallucination(text: str, context: Dict, llm_service) -> Dict:
    """
    AI ìƒì„± ë¯¼ì›ì˜ í™˜ê° ê°€ëŠ¥ì„± íƒì§€
    
    Args:
        text: ë¯¼ì› ì›ë¬¸
        context: ê´€ë ¨ ë²•ë ¹, ì ˆì°¨ ë“±ì˜ ë§¥ë½ ì •ë³´
        llm_service: LLM ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
    
    Returns:
        í™˜ê° íƒì§€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    suspicious_parts = []
    
    # 1. íŒ¨í„´ ê¸°ë°˜ íƒì§€
    pattern_issues = _detect_by_patterns(text)
    suspicious_parts.extend(pattern_issues)
    
    # 2. LLM ê¸°ë°˜ êµì°¨ ê²€ì¦
    llm_issues = _detect_by_llm(text, context, llm_service)
    suspicious_parts.extend(llm_issues)
    
    # 3. ìœ„í—˜ë„ ê³„ì‚°
    risk_level, overall_score = _calculate_risk_level(suspicious_parts)
    
    # 4. ê²€ì¦ í•„ìš” í•­ëª© ì¶”ì¶œ
    verification_needed = _extract_verification_items(suspicious_parts)
    
    return {
        "risk_level": risk_level,
        "suspicious_parts": suspicious_parts,
        "verification_needed": verification_needed,
        "overall_score": overall_score,
        "total_issues_found": len(suspicious_parts)
    }


def _detect_by_patterns(text: str) -> List[Dict]:
    """íŒ¨í„´ ê¸°ë°˜ í™˜ê° íƒì§€"""
    issues = []
    lines = text.split('\n')
    
    # 1. ë‚ ì§œ ê²€ì¦
    date_pattern = r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼'
    for i, line in enumerate(lines, 1):
        for match in re.finditer(date_pattern, line):
            year, month, day = map(int, match.groups())
            if not _is_valid_date(year, month, day):
                issues.append({
                    "text": match.group(0),
                    "reason": f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë‚ ì§œ (ì˜ˆ: {month}ì›”ì€ {day}ì¼ê¹Œì§€ ì—†ìŒ)",
                    "confidence": 0.95,
                    "line_number": i,
                    "category": "invalid_date"
                })
    
    # 2. ë²•ë ¹ ì¡°í•­ ê²€ì¦ (ê¸°ë³¸ íŒ¨í„´ë§Œ)
    law_pattern = r'([ê°€-í£\s]+ë²•)\s*ì œ\s*(\d+)ì¡°'
    for i, line in enumerate(lines, 1):
        for match in re.finditer(law_pattern, line):
            law_name, article_num = match.groups()
            article_num = int(article_num)
            # ë¹„í˜„ì‹¤ì ìœ¼ë¡œ í° ì¡°í•­ ë²ˆí˜¸
            if article_num > 500:
                issues.append({
                    "text": match.group(0),
                    "reason": f"ë¹„í˜„ì‹¤ì ìœ¼ë¡œ í° ì¡°í•­ ë²ˆí˜¸ (ì œ{article_num}ì¡°)",
                    "confidence": 0.75,
                    "line_number": i,
                    "category": "suspicious_law_reference"
                })
    
    # 3. ê³¼ë„í•˜ê²Œ ì •í™•í•œ ìˆ˜ì¹˜
    precise_number_pattern = r'\d+\.\d{4,}%'
    for i, line in enumerate(lines, 1):
        for match in re.finditer(precise_number_pattern, line):
            issues.append({
                "text": match.group(0),
                "reason": "AIê°€ ì§€ì–´ë‚¸ ê²ƒìœ¼ë¡œ ì˜ì‹¬ë˜ëŠ” ê³¼ë„í•˜ê²Œ ì •í™•í•œ í†µê³„",
                "confidence": 0.65,
                "line_number": i,
                "category": "overly_precise_stats"
            })
    
    # 4. ëª¨ìˆœëœ ìˆ˜ì¹˜
    amount_mentions = re.findall(r'(\d{1,3}(?:,\d{3})*)\s*ì›', text)
    if len(amount_mentions) > 1:
        amounts = [int(amt.replace(',', '')) for amt in amount_mentions]
        if len(set(amounts)) > 1 and max(amounts) / min(amounts) > 10:
            issues.append({
                "text": f"ê¸ˆì•¡ ì–¸ê¸‰: {', '.join(amount_mentions)}ì›",
                "reason": "ë¬¸ì„œ ë‚´ ê¸ˆì•¡ì´ ì¼ê´€ë˜ì§€ ì•ŠìŒ (10ë°° ì´ìƒ ì°¨ì´)",
                "confidence": 0.70,
                "line_number": 0,
                "category": "inconsistent_amounts"
            })
    
    return issues


def _detect_by_llm(text: str, context: Dict, llm_service) -> List[Dict]:
    """LLM ê¸°ë°˜ í™˜ê° íƒì§€"""
    
    law_context = context.get('law', '')[:2000]  # í† í° ì œí•œ
    
    prompt = f"""
ë‹¹ì‹ ì€ í–‰ì • ë¯¼ì› ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¯¼ì› ë‚´ìš©ì—ì„œ AIê°€ ìƒì„±í•œ í™˜ê°(í—ˆìœ„/ë¶€ì •í™• ì •ë³´) ê°€ëŠ¥ì„±ì´ ìˆëŠ” ë¶€ë¶„ì„ ì°¾ì•„ì£¼ì„¸ìš”.

**ë¯¼ì› ë‚´ìš©**:
{text[:3000]}

**ê´€ë ¨ ë²•ë ¹ (ì°¸ê³ ìš©)**:
{law_context}

**ê²€ì¦ ê¸°ì¤€**:
1. ë²•ë ¹/ì¡°ë¡€ ì¸ìš©ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€
2. í–‰ì • ì ˆì°¨ ì„œìˆ ì´ ì‹¤ë¬´ì™€ ì¼ì¹˜í•˜ëŠ”ì§€
3. ë‚ ì§œ/ê¸°ê°„ì´ ë…¼ë¦¬ì ìœ¼ë¡œ íƒ€ë‹¹í•œì§€
4. ìˆ˜ì¹˜ ë°ì´í„°ê°€ í•©ë¦¬ì ì¸ì§€

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "issues": [
    {{
      "text": "ì˜ì‹¬ë˜ëŠ” êµ¬ì²´ì ì¸ ë¬¸ì¥",
      "reason": "ì™œ ì˜ì‹¬ë˜ëŠ”ì§€ ì„¤ëª…",
      "confidence": 0.0~1.0,
      "category": "law_reference|procedure|date|number"
    }}
  ]
}}

**ì¤‘ìš”**: í™•ì‹¤í•œ ì˜¤ë¥˜ë§Œ ì§€ì í•˜ì„¸ìš”. ì• ë§¤í•œ ê²½ìš°ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""
    
    try:
        response = llm_service.generate_text(prompt, temperature=0.3)
        result = _safe_json_loads(response)
        
        if result and 'issues' in result:
            # line_numberëŠ” 0ìœ¼ë¡œ ì„¤ì • (LLMì€ ì¤„ ë²ˆí˜¸ë¥¼ ì•Œ ìˆ˜ ì—†ìŒ)
            for issue in result['issues']:
                issue['line_number'] = 0
            return result['issues']
    except Exception as e:
        print(f"LLM íƒì§€ ì˜¤ë¥˜: {e}")
    
    return []


def _is_valid_date(year: int, month: int, day: int) -> bool:
    """ë‚ ì§œ ìœ íš¨ì„± ê²€ì¦"""
    try:
        datetime(year, month, day)
        # ë¯¸ë˜ ë‚ ì§œ ì²´í¬ (ë„ˆë¬´ ë¨¼ ë¯¸ë˜ëŠ” ì˜ì‹¬)
        target_date = datetime(year, month, day)
        if target_date > datetime.now().replace(year=datetime.now().year + 10):
            return False
        return True
    except ValueError:
        return False


def _calculate_risk_level(suspicious_parts: List[Dict]) -> Tuple[str, float]:
    """ìœ„í—˜ë„ ê³„ì‚°"""
    if not suspicious_parts:
        return "low", 1.0
    
    # ê°€ì¤‘ì¹˜ ì ìš©
    total_weight = 0
    for part in suspicious_parts:
        confidence = part.get('confidence', 0.5)
        category = part.get('category', '')
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê°€ì¤‘ì¹˜
        category_weight = {
            'invalid_date': 1.5,
            'suspicious_law_reference': 1.3,
            'overly_precise_stats': 0.8,
            'inconsistent_amounts': 1.2,
            'law_reference': 1.4,
            'procedure': 1.1,
        }.get(category, 1.0)
        
        total_weight += confidence * category_weight
    
    # ì •ê·œí™” (ì´ìŠˆ ê°œìˆ˜ ê³ ë ¤)
    normalized_score = total_weight / max(len(suspicious_parts), 1)
    
    # ì‹ ë¢°ë„ ì ìˆ˜ (ì—­ìˆ˜)
    overall_score = max(0, 1 - normalized_score)
    
    # ìœ„í—˜ë„ ë¶„ë¥˜
    if normalized_score >= 1.0 or len(suspicious_parts) >= 5:
        risk_level = "high"
    elif normalized_score >= 0.5 or len(suspicious_parts) >= 2:
        risk_level = "medium"
    else:
        risk_level = "low"
    
    return risk_level, overall_score


def _extract_verification_items(suspicious_parts: List[Dict]) -> List[str]:
    """ê²€ì¦ì´ í•„ìš”í•œ í•­ëª© ì¶”ì¶œ"""
    items = []
    for part in suspicious_parts:
        category = part.get('category', '')
        text = part.get('text', '')[:50]
        
        if category == 'invalid_date':
            items.append(f"ë‚ ì§œ í™•ì¸: {text}")
        elif category in ['suspicious_law_reference', 'law_reference']:
            items.append(f"ë²•ë ¹ ì‹¤ì¡´ í™•ì¸: {text}")
        elif category == 'inconsistent_amounts':
            items.append("ë¬¸ì„œ ë‚´ ê¸ˆì•¡ ì¼ê´€ì„± ì¬í™•ì¸")
        else:
            items.append(f"ì‚¬ì‹¤ ê´€ê³„ í™•ì¸: {text}")
    
    return list(set(items))  # ì¤‘ë³µ ì œê±°


def _safe_json_loads(text: str) -> Optional[Dict]:
    """ì•ˆì „í•œ JSON íŒŒì‹±"""
    if not text:
        return None
    try:
        return json.loads(text)
    except:
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                return json.loads(match.group(0))
        except:
            pass
    return None


# =========================================================
# 2) ì—…ë¬´ íš¨ìœ¨í™” í•¨ìˆ˜
# =========================================================

def analyze_petition_priority(petition_text: str, detection_result: Dict, llm_service) -> Dict:
    """ë¯¼ì› ê¸´ê¸‰ë„ ë° ì²˜ë¦¬ ìš°ì„ ìˆœìœ„ ìë™ íŒë‹¨"""
    
    risk_level = detection_result.get('risk_level', 'low')
    
    prompt = f"""
ë‹¹ì‹ ì€ í–‰ì • ë¯¼ì› ì²˜ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¯¼ì›ì˜ ì²˜ë¦¬ ìš°ì„ ìˆœìœ„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

**ë¯¼ì› ë‚´ìš©**:
{petition_text[:2000]}

**í™˜ê° ìœ„í—˜ë„**: {risk_level}

**íŒë‹¨ ê¸°ì¤€**:
1. ê¸´ê¸‰ì„±: ë²•ì • ê¸°í•œ, ì¸ëª…/ì¬ì‚° ê´€ë ¨, ì–¸ë¡  ë³´ë„ ê°€ëŠ¥ì„±
2. ì—…ë¬´ ë³µì¡ë„: ê´€ë ¨ ë¶€ì„œ ìˆ˜, í•„ìš” ì ˆì°¨, ë²•ë ¹ ê²€í†  ë²”ìœ„
3. ë¯¼ì›ì¸ ê¶Œë¦¬ ì¹¨í•´ ì •ë„
4. í™˜ê° ìœ„í—˜ë„ (ë†’ìœ¼ë©´ ê²€ì¦ ì‹œê°„ ì¶”ê°€ í•„ìš”)

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "priority": "urgent|high|normal|low",
  "estimated_workload": "ê°„í¸|ë³´í†µ|ë³µì¡",
  "recommended_deadline": "YYYY-MM-DD",
  "required_departments": ["ë¶€ì„œ1", "ë¶€ì„œ2"],
  "auto_tags": ["íƒœê·¸1", "íƒœê·¸2"],
  "reasoning": "íŒë‹¨ ê·¼ê±° 2-3ì¤„"
}}

**ìš°ì„ ìˆœìœ„ ì •ì˜**:
- urgent: 24ì‹œê°„ ë‚´ ì²˜ë¦¬ (ë²•ì • ê¸°í•œ ì„ë°•, ê¸´ê¸‰ìƒí™©)
- high: 3ì¼ ë‚´ ì²˜ë¦¬ (ì¤‘ìš”ë„ ë†’ìŒ, ë¯¼ì›ì¸ ê¶Œë¦¬ ê´€ë ¨)
- normal: 7ì¼ ë‚´ ì²˜ë¦¬ (ì¼ë°˜ì ì¸ ë¯¼ì›)
- low: 14ì¼ ë‚´ ì²˜ë¦¬ (ë‹¨ìˆœ ë¬¸ì˜, ì •ë³´ ì œê³µ)
"""
    
    try:
        response = llm_service.generate_text(prompt, temperature=0.3)
        result = _safe_json_loads(response)
        
        if result:
            # ê¸°ë³¸ê°’ ì„¤ì •
            result.setdefault('priority', 'normal')
            result.setdefault('estimated_workload', 'ë³´í†µ')
            result.setdefault('recommended_deadline', 
                            (datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d'))
            result.setdefault('required_departments', ['ë‹´ë‹¹ë¶€ì„œ'])
            result.setdefault('auto_tags', [])
            result.setdefault('reasoning', '')
            
            return result
    except Exception as e:
        print(f"ìš°ì„ ìˆœìœ„ ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    # ê¸°ë³¸ê°’ ë°˜í™˜
    return {
        "priority": "normal",
        "estimated_workload": "ë³´í†µ",
        "recommended_deadline": (datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d'),
        "required_departments": ["ë‹´ë‹¹ë¶€ì„œ"],
        "auto_tags": [],
        "reasoning": "ìë™ ë¶„ì„ ì‹¤íŒ¨, ìˆ˜ë™ ê²€í†  í•„ìš”"
    }


def generate_processing_checklist(analysis_result: Dict, llm_service) -> List[Dict]:
    """ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¨ê³„ë³„ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
    
    petition = analysis_result.get('petition', '')
    detection = analysis_result.get('detection', {})
    priority = analysis_result.get('priority', {})
    
    risk_level = detection.get('risk_level', 'low')
    
    prompt = f"""
ë‹¤ìŒ ë¯¼ì›ì— ëŒ€í•œ ì²˜ë¦¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¨ê³„ë³„ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

**ë¯¼ì› ë‚´ìš©**: {petition[:1500]}
**í™˜ê° ìœ„í—˜ë„**: {risk_level}
**ìš°ì„ ìˆœìœ„**: {priority.get('priority', 'normal')}

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
  "steps": [
    {{
      "step": 1,
      "title": "ë‹¨ê³„ ì œëª©",
      "items": [
        {{"task": "êµ¬ì²´ì ì¸ ì‘ì—…", "completed": false}},
        {{"task": "êµ¬ì²´ì ì¸ ì‘ì—…", "completed": false}}
      ],
      "deadline": "ì ‘ìˆ˜ í›„ Nì¼ ì´ë‚´"
    }}
  ]
}}

**ë°˜ë“œì‹œ í¬í•¨í•  ë‹¨ê³„**:
1. ë¯¼ì› ë‚´ìš© ê²€ì¦ (í™˜ê° ìœ„í—˜ë„ ë†’ìœ¼ë©´ ì‚¬ì‹¤ í™•ì¸ ê°•í™”)
2. ê´€ë ¨ ë²•ë ¹ ë° ê·œì • ê²€í† 
3. ìœ ê´€ ë¶€ì„œ í˜‘ì˜ (í•„ìš”ì‹œ)
4. ì²˜ë¦¬ ë°©ì•ˆ ê²°ì •
5. íšŒì‹ ë¬¸ ì‘ì„± ë° ë°œì†¡

ê° ë‹¨ê³„ëŠ” 3-5ê°œì˜ êµ¬ì²´ì ì¸ ì‘ì—…ìœ¼ë¡œ ë‚˜ëˆ„ì„¸ìš”.
"""
    
    try:
        response = llm_service.generate_text(prompt, temperature=0.4)
        result = _safe_json_loads(response)
        
        if result and 'steps' in result:
            return result['steps']
    except Exception as e:
        print(f"ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
    
    # ê¸°ë³¸ ì²´í¬ë¦¬ìŠ¤íŠ¸
    return [
        {
            "step": 1,
            "title": "ë¯¼ì› ì ‘ìˆ˜ ë° ê²€ì¦",
            "items": [
                {"task": "ë¯¼ì› ë‚´ìš© ì •í™•ì„± í™•ì¸", "completed": False},
                {"task": "ì²¨ë¶€ ì„œë¥˜ ì§„ìœ„ í™•ì¸", "completed": False}
            ],
            "deadline": "ì ‘ìˆ˜ í›„ 1ì¼ ì´ë‚´"
        },
        {
            "step": 2,
            "title": "ê´€ë ¨ ë²•ë ¹ ê²€í† ",
            "items": [
                {"task": "ì ìš© ë²•ë ¹ í™•ì¸", "completed": False},
                {"task": "íŒë¡€ ë° ì„ ë¡€ ì¡°ì‚¬", "completed": False}
            ],
            "deadline": "ì ‘ìˆ˜ í›„ 3ì¼ ì´ë‚´"
        },
        {
            "step": 3,
            "title": "ì²˜ë¦¬ ë°©ì•ˆ ê²°ì •",
            "items": [
                {"task": "ì²˜ë¦¬ ë°©í–¥ ì„¤ì •", "completed": False},
                {"task": "ê²°ì¬ ì§„í–‰", "completed": False}
            ],
            "deadline": "ì ‘ìˆ˜ í›„ 5ì¼ ì´ë‚´"
        },
        {
            "step": 4,
            "title": "íšŒì‹  ë° ì¢…ê²°",
            "items": [
                {"task": "íšŒì‹ ë¬¸ ì‘ì„±", "completed": False},
                {"task": "ë¯¼ì›ì¸ì—ê²Œ í†µë³´", "completed": False}
            ],
            "deadline": "ì ‘ìˆ˜ í›„ 7ì¼ ì´ë‚´"
        }
    ]


def generate_response_draft(petition_text: str, analysis: Dict, 
                            response_type: str, llm_service) -> str:
    """ë¯¼ì› íšŒì‹ ë¬¸ ìë™ ì´ˆì•ˆ ìƒì„±"""
    
    response_type_kr = {
        "approval": "ìŠ¹ì¸/ìˆ˜ìš©",
        "rejection": "ë¶ˆê°€/ê±°ë¶€",
        "partial": "ë¶€ë¶„ ìˆ˜ìš©",
        "request_info": "ë³´ì™„ ìš”ì²­"
    }.get(response_type, "ì¼ë°˜ íšŒì‹ ")
    
    detection = analysis.get('detection', {})
    priority = analysis.get('priority', {})
    
    prompt = f"""
ë‹¤ìŒ ë¯¼ì›ì— ëŒ€í•œ **{response_type_kr}** íšŒì‹ ë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë¯¼ì› ë‚´ìš©**:
{petition_text[:2000]}

**í™˜ê° íƒì§€ ê²°ê³¼**: {detection.get('risk_level', 'low')}
**ì²˜ë¦¬ ìš°ì„ ìˆœìœ„**: {priority.get('priority', 'normal')}

**íšŒì‹ ë¬¸ ì‘ì„± ê·œì¹™**:
1. í–‰ì •ì•ˆì „ë¶€ ê³µë¬¸ì„œ ì‘ì„± ê¸°ì¤€ ì¤€ìˆ˜
2. ë²•ì  ê·¼ê±° ëª…ì‹œ (êµ¬ì²´ì ì¸ ë²•ë ¹ëª…, ì¡°í•­)
3. ì²˜ë¦¬ ê²°ê³¼ ë° ì‚¬ìœ  ëª…í™•íˆ ê¸°ìˆ 
4. ë¯¼ì›ì¸ ê¶Œë¦¬ êµ¬ì œ ë°©ë²• ì•ˆë‚´ (ê±°ë¶€ ì‹œ)
5. ë‹´ë‹¹ì ì—°ë½ì²˜ í¬í•¨

**í˜•ì‹**:
---
[ì œëª©]
(ê°„ê²°í•˜ê³  ëª…í™•í•œ ì œëª©)

[ë³¸ë¬¸]
1. ë¯¼ì› ìš”ì§€ ìš”ì•½ (1-2ì¤„)
2. ì²˜ë¦¬ ê²°ê³¼ ë° ë²•ì  ê·¼ê±°
3. êµ¬ì²´ì ì¸ ì²˜ë¦¬ ë‚´ìš©/ë¶ˆê°€ ì‚¬ìœ 
4. í–¥í›„ ì¡°ì¹˜ ë˜ëŠ” êµ¬ì œ ë°©ë²•
5. ë¬¸ì˜ì²˜

[ì²¨ë¶€]
(í•„ìš”í•œ ê²½ìš°)
---

**ì£¼ì˜ì‚¬í•­**:
- ê³µì†í•˜ê³  ëª…í™•í•œ ì–´ì¡°
- ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ ì„¤ëª…
- {response_type_kr} ì‚¬ìœ ë¥¼ ì„¤ë“ë ¥ ìˆê²Œ ì„¤ëª…
"""
    
    try:
        response = llm_service.generate_text(prompt, temperature=0.5)
        return response
    except Exception as e:
        print(f"íšŒì‹ ë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return f"""
[ì œëª©] {response_type_kr} íšŒì‹ 

[ë³¸ë¬¸]
ê·€í•˜ê»˜ì„œ ì œì¶œí•˜ì‹  ë¯¼ì›ì— ëŒ€í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ íšŒì‹ ë“œë¦½ë‹ˆë‹¤.

(ìë™ ìƒì„± ì‹¤íŒ¨: {str(e)})
ë‹´ë‹¹ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ë¬¸ì˜ì²˜]
ë‹´ë‹¹: [ë¶€ì„œëª…] [ë‹´ë‹¹ì]
ì—°ë½ì²˜: [ì „í™”ë²ˆí˜¸]
ì´ë©”ì¼: [ì´ë©”ì¼]
"""


# =========================================================
# 3) UI ë Œë”ë§ í•¨ìˆ˜
# =========================================================

def render_hallucination_report(detection_result: Dict):
    """í™˜ê° íƒì§€ ê²°ê³¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ"""
    
    risk_colors = {
        "high": "#dc2626",    # ë¹¨ê°•
        "medium": "#f59e0b",  # ì£¼í™©
        "low": "#10b981"      # ì´ˆë¡
    }
    
    risk_level = detection_result.get('risk_level', 'low')
    color = risk_colors[risk_level]
    overall_score = detection_result.get('overall_score', 0.5)
    total_issues = detection_result.get('total_issues_found', 0)
    
    risk_labels = {
        "high": "ë†’ìŒ âš ï¸",
        "medium": "ì¤‘ê°„ âš¡",
        "low": "ë‚®ìŒ âœ…"
    }
    
    st.markdown(f"""
    <div style='background: linear-gradient(135deg, {color}22 0%, {color}11 100%);
                padding: 1.5rem; border-radius: 12px; border-left: 4px solid {color};
                margin: 1rem 0;'>
        <h4 style='margin: 0 0 1rem 0; color: {color};'>
            ğŸ” AI í™˜ê° íƒì§€ ê²°ê³¼
        </h4>
        <div style='display: flex; gap: 2rem; flex-wrap: wrap;'>
            <div>
                <p style='margin: 0; color: #6b7280; font-size: 0.85rem;'>ì‹ ë¢°ë„ ì ìˆ˜</p>
                <p style='margin: 0.25rem 0 0 0; color: #1f2937; font-size: 1.5rem; font-weight: 700;'>
                    {overall_score*100:.1f}%
                </p>
            </div>
            <div>
                <p style='margin: 0; color: #6b7280; font-size: 0.85rem;'>ìœ„í—˜ë„</p>
                <p style='margin: 0.25rem 0 0 0; color: {color}; font-size: 1.5rem; font-weight: 700;'>
                    {risk_labels[risk_level]}
                </p>
            </div>
            <div>
                <p style='margin: 0; color: #6b7280; font-size: 0.85rem;'>ë°œê²¬ëœ ì´ìŠˆ</p>
                <p style='margin: 0.25rem 0 0 0; color: #1f2937; font-size: 1.5rem; font-weight: 700;'>
                    {total_issues}ê±´
                </p>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # ì˜ì‹¬ êµ¬ê°„ í‘œì‹œ
    suspicious_parts = detection_result.get('suspicious_parts', [])
    if suspicious_parts:
        st.warning(f"âš ï¸ **{len(suspicious_parts)}ê°œì˜ ì˜ì‹¬ êµ¬ê°„ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.** ì•„ë˜ ë‚´ìš©ì„ ê²€ì¦í•˜ì„¸ìš”:")
        
        for i, part in enumerate(suspicious_parts, 1):
            with st.expander(f"ğŸ” ì˜ì‹¬ êµ¬ê°„ {i}: {part['text'][:60]}{'...' if len(part['text']) > 60 else ''}"):
                st.markdown(f"**ì „ì²´ ë‚´ìš©**: `{part['text']}`")
                st.markdown(f"**íƒì§€ ì´ìœ **: {part['reason']}")
                st.markdown(f"**ì‹ ë¢°ë„**: {part['confidence']*100:.1f}%")
                
                if part.get('line_number', 0) > 0:
                    st.markdown(f"**ìœ„ì¹˜**: {part['line_number']}ë²ˆì§¸ ì¤„")
                
                category_labels = {
                    'invalid_date': 'ë‚ ì§œ ì˜¤ë¥˜',
                    'suspicious_law_reference': 'ë²•ë ¹ ì°¸ì¡° ì˜ì‹¬',
                    'overly_precise_stats': 'ê³¼ë„í•œ í†µê³„',
                    'inconsistent_amounts': 'ê¸ˆì•¡ ë¶ˆì¼ì¹˜',
                    'law_reference': 'ë²•ë ¹ ê²€ì¦ í•„ìš”',
                    'procedure': 'ì ˆì°¨ ê²€ì¦ í•„ìš”'
                }
                category = part.get('category', '')
                if category:
                    st.caption(f"ì¹´í…Œê³ ë¦¬: {category_labels.get(category, category)}")
    
    # ê²€ì¦ í•„ìš” í•­ëª©
    verification_needed = detection_result.get('verification_needed', [])
    if verification_needed:
        st.info("ğŸ“‹ **ê²€ì¦ì´ í•„ìš”í•œ í•­ëª©**:")
        for item in verification_needed:
            st.markdown(f"- {item}")


# =========================================================
# 4) ìºì‹± ë° ìœ í‹¸ë¦¬í‹°
# =========================================================

@st.cache_data(ttl=3600)
def _detect_hallucination_cached_core(text_hash: str, text: str, context_json: str) -> Dict:
    """
    ë‚´ë¶€ ìºì‹± í•¨ìˆ˜ - llm_service ì—†ì´ í˜¸ì¶œ
    
    ì£¼ì˜: llm_serviceëŠ” í•´ì‹œ ë¶ˆê°€ëŠ¥(pickle ë¶ˆê°€)í•˜ë¯€ë¡œ ìºì‹± ëŒ€ìƒì—ì„œ ì œì™¸
    """
    # LLM ê¸°ë°˜ íƒì§€ëŠ” ìºì‹±í•˜ì§€ ì•Šê³ , íŒ¨í„´ ê¸°ë°˜ë§Œ ìºì‹±
    context = json.loads(context_json) if context_json else {}
    
    suspicious_parts = []
    # íŒ¨í„´ ê¸°ë°˜ íƒì§€ë§Œ ìˆ˜í–‰ (ë¹ ë¥´ê³  ê²°ì •ì )
    suspicious_parts.extend(_detect_by_patterns(text))
    
    # ìœ„í—˜ë„ ê³„ì‚°
    risk_level, overall_score = _calculate_risk_level(suspicious_parts)
    
    # ê²€ì¦ í•„ìš” í•­ëª© ì¶”ì¶œ
    verification_needed = _extract_verification_items(suspicious_parts)
    
    return {
        "risk_level": risk_level,
        "suspicious_parts": suspicious_parts,
        "verification_needed": verification_needed,
        "overall_score": overall_score,
        "total_issues_found": len(suspicious_parts),
        "cached": True  # ìºì‹±ëœ ê²°ê³¼ì„ì„ í‘œì‹œ
    }


def detect_hallucination_cached(text_hash: str, text: str, context: Dict, llm_service) -> Dict:
    """
    ìºì‹±ëœ í™˜ê° íƒì§€ (ë™ì¼ ë¯¼ì› ì¤‘ë³µ ê²€ì¦ ë°©ì§€)
    
    ì „ëµ:
    1. íŒ¨í„´ ê¸°ë°˜ íƒì§€ëŠ” ìºì‹± (ë¹ ë¥´ê³  ê²°ì •ì )
    2. LLM ê¸°ë°˜ íƒì§€ëŠ” ë§¤ë²ˆ ì‹¤í–‰ (llm_service ê°ì²´ëŠ” pickle ë¶ˆê°€)
    
    Args:
        text_hash: í…ìŠ¤íŠ¸ í•´ì‹œ (ìºì‹± í‚¤)
        text: ë¯¼ì› ì›ë¬¸
        context: ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸
        llm_service: LLM ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ìºì‹± ì œì™¸)
    """
    # 1. íŒ¨í„´ ê¸°ë°˜ íƒì§€ (ìºì‹±)
    context_json = json.dumps(context, ensure_ascii=False) if context else ""
    cached_result = _detect_hallucination_cached_core(text_hash, text, context_json)
    
    # 2. LLM ê¸°ë°˜ íƒì§€ (ë§¤ë²ˆ ì‹¤í–‰ - ìºì‹± ì•ˆ í•¨)
    try:
        llm_issues = _detect_by_llm(text, context, llm_service)
        
        # ê²°ê³¼ ë³‘í•©
        all_suspicious = cached_result['suspicious_parts'] + llm_issues
        
        # ì¤‘ë³µ ì œê±° (ë™ì¼ í…ìŠ¤íŠ¸)
        seen_texts = set()
        unique_suspicious = []
        for part in all_suspicious:
            part_text = part.get('text', '')
            if part_text not in seen_texts:
                seen_texts.add(part_text)
                unique_suspicious.append(part)
        
        # ì¬ê³„ì‚°
        risk_level, overall_score = _calculate_risk_level(unique_suspicious)
        verification_needed = _extract_verification_items(unique_suspicious)
        
        return {
            "risk_level": risk_level,
            "suspicious_parts": unique_suspicious,
            "verification_needed": verification_needed,
            "overall_score": overall_score,
            "total_issues_found": len(unique_suspicious),
            "cached": False
        }
    except Exception as e:
        # LLM ì˜¤ë¥˜ ì‹œ ìºì‹±ëœ ê²°ê³¼ë§Œ ë°˜í™˜
        print(f"LLM íƒì§€ ì˜¤ë¥˜ (íŒ¨í„´ ê¸°ë°˜ ê²°ê³¼ë§Œ ì‚¬ìš©): {e}")
        return cached_result


def get_text_hash(text: str) -> str:
    """í…ìŠ¤íŠ¸ í•´ì‹œ ìƒì„±"""
    return hashlib.sha256(text.encode('utf-8')).hexdigest()
